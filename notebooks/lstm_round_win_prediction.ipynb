{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d809704",
   "metadata": {},
   "source": [
    "# CS:GO Round Win Prediction with LSTM\n",
    "\n",
    "This notebook demonstrates how to use the LSTM model to predict CS:GO round outcomes. The model processes sequential data from round frames and outputs win probabilities for each frame within the round."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e66133",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, let's import the necessary libraries and set up our environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80bf3812",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import seaborn as sns\n",
    "\n",
    "# Import our package\n",
    "from mbml.model import LSTMWinPredictor\n",
    "from mbml.dataset import create_dataloaders\n",
    "from mbml.train import train_model\n",
    "from mbml.predict import batch_predict_rounds, visualize_round_predictions\n",
    "\n",
    "# Set the paths\n",
    "CSV_PATH = \"../round_frame_data.csv\"\n",
    "MODEL_DIR = \"../models/lstm_notebook\"\n",
    "OUTPUT_DIR = \"../reports/figures/notebook_examples\"\n",
    "\n",
    "# Create directories\n",
    "Path(MODEL_DIR).mkdir(parents=True, exist_ok=True)\n",
    "Path(OUTPUT_DIR).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d3f8c4",
   "metadata": {},
   "source": [
    "## 1. Explore the Data\n",
    "\n",
    "Let's first take a look at the data to understand its structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e754870",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load first few rows of the CSV file\n",
    "df = pd.read_csv(CSV_PATH, nrows=1000)\n",
    "print(f\"DataFrame shape: {df.shape}\")\n",
    "print(f\"\\nColumns:\\n{df.columns.tolist()}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc7ecda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data types and basic statistics\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19fff56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore round distribution\n",
    "round_counts = df.groupby(['match_id', 'round_idx']).size()\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(round_counts, kde=True)\n",
    "plt.title('Distribution of Frames per Round')\n",
    "plt.xlabel('Number of Frames')\n",
    "plt.ylabel('Count')\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(f\"Average frames per round: {round_counts.mean():.1f}\")\n",
    "print(f\"Minimum frames per round: {round_counts.min()}\")\n",
    "print(f\"Maximum frames per round: {round_counts.max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1238127",
   "metadata": {},
   "source": [
    "## 2. Create Dataloaders\n",
    "\n",
    "Now let's create dataloaders to handle our data efficiently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ea88eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataloaders\n",
    "train_loader, val_loader, test_loader = create_dataloaders(\n",
    "    csv_path=CSV_PATH,\n",
    "    batch_size=32,\n",
    "    train_ratio=0.7,\n",
    "    val_ratio=0.15,\n",
    "    test_ratio=0.15,\n",
    "    preload=True  # Set to False for very large datasets\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df7fe5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine a batch\n",
    "batch = next(iter(train_loader))\n",
    "print(f\"Batch keys: {batch.keys()}\")\n",
    "print(f\"Features shape: {batch['features'].shape}\")  # [batch_size, max_seq_len, input_dim]\n",
    "print(f\"Labels shape: {batch['labels'].shape}\")     # [batch_size, max_seq_len]\n",
    "print(f\"Mask shape: {batch['mask'].shape}\")         # [batch_size, max_seq_len]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d831d3b9",
   "metadata": {},
   "source": [
    "## 3. Create and Train the Model\n",
    "\n",
    "Now, let's create and train our LSTM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4696e064",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get input dimension from data\n",
    "input_dim = batch['features'].shape[-1]\n",
    "print(f\"Input dimension: {input_dim}\")\n",
    "\n",
    "# Set model hyperparameters\n",
    "hidden_dim = 64\n",
    "num_layers = 2\n",
    "dropout = 0.2\n",
    "\n",
    "# Create model\n",
    "model = LSTMWinPredictor(\n",
    "    input_dim=input_dim,\n",
    "    hidden_dim=hidden_dim,\n",
    "    num_layers=num_layers,\n",
    "    dropout=dropout\n",
    ")\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97fffeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if model already exists\n",
    "model_path = os.path.join(MODEL_DIR, \"best_model.pt\")\n",
    "\n",
    "if os.path.exists(model_path):\n",
    "    print(f\"Loading existing model from {model_path}\")\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "else:\n",
    "    print(f\"Training new model\")\n",
    "    train_results = train_model(\n",
    "        csv_path=CSV_PATH,\n",
    "        model_save_dir=MODEL_DIR,\n",
    "        input_dim=input_dim,\n",
    "        hidden_dim=hidden_dim,\n",
    "        num_layers=num_layers,\n",
    "        dropout=dropout,\n",
    "        batch_size=32,\n",
    "        num_epochs=10,  # Lower for demonstration\n",
    "        learning_rate=0.001,\n",
    "        patience=3\n",
    "    )\n",
    "    \n",
    "    # Load the best model\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f18a668",
   "metadata": {},
   "source": [
    "## 4. Evaluate and Visualize\n",
    "\n",
    "Now let's evaluate the model and visualize the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455b9966",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move model to device\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Get a test batch\n",
    "test_batch = next(iter(test_loader))\n",
    "features = test_batch['features'].to(device)\n",
    "labels = test_batch['labels']\n",
    "mask = test_batch['mask']\n",
    "metadata = test_batch['metadata']\n",
    "\n",
    "# Make predictions\n",
    "with torch.no_grad():\n",
    "    predictions = model(features).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b784db75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize predictions for a few examples\n",
    "n_examples = 3  # Number of examples to visualize\n",
    "\n",
    "for i in range(min(n_examples, len(metadata))):\n",
    "    # Get data for this example\n",
    "    example_preds = predictions[i]\n",
    "    example_labels = labels[i]\n",
    "    example_mask = mask[i]\n",
    "    match_id, round_idx = metadata[i]\n",
    "    \n",
    "    # Get non-padded values\n",
    "    valid_preds = example_preds[example_mask > 0]\n",
    "    valid_labels = example_labels[example_mask > 0]\n",
    "    \n",
    "    # Create visualization\n",
    "    fig_path = os.path.join(OUTPUT_DIR, f\"example_{i}_match_{match_id}_round_{round_idx}.png\")\n",
    "    \n",
    "    fig = visualize_round_predictions(\n",
    "        predictions=valid_preds,\n",
    "        labels=valid_labels,\n",
    "        match_id=match_id,\n",
    "        round_idx=round_idx,\n",
    "        save_path=fig_path\n",
    "    )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d141ea9",
   "metadata": {},
   "source": [
    "## 5. Calculate Performance Metrics\n",
    "\n",
    "Let's calculate some performance metrics for the model on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70b8f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "def evaluate_batch(predictions, labels, mask, threshold=0.5):\n",
    "    \"\"\"Evaluate predictions for a batch.\"\"\"\n",
    "    # Flatten tensors and apply mask\n",
    "    flat_preds = predictions.view(-1)[mask.view(-1) > 0].numpy()\n",
    "    flat_labels = labels.view(-1)[mask.view(-1) > 0].numpy()\n",
    "    \n",
    "    # Convert to binary predictions\n",
    "    binary_preds = (flat_preds >= threshold).astype(int)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    metrics = {\n",
    "        'accuracy': accuracy_score(flat_labels, binary_preds),\n",
    "        'precision': precision_score(flat_labels, binary_preds, zero_division=0),\n",
    "        'recall': recall_score(flat_labels, binary_preds, zero_division=0),\n",
    "        'f1': f1_score(flat_labels, binary_preds, zero_division=0),\n",
    "        'roc_auc': roc_auc_score(flat_labels, flat_preds) if len(np.unique(flat_labels)) > 1 else np.nan\n",
    "    }\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# Evaluate the batch\n",
    "metrics = evaluate_batch(predictions, labels, mask)\n",
    "\n",
    "print(\"\\nPerformance Metrics (Test Batch):\")\n",
    "for metric, value in metrics.items():\n",
    "    print(f\"{metric.capitalize()}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38bc5fd2",
   "metadata": {},
   "source": [
    "## 6. Conclusion\n",
    "\n",
    "In this notebook, we've demonstrated how to:\n",
    "\n",
    "1. Load and explore CS:GO round data\n",
    "2. Create PyTorch dataloaders with proper padding for variable-length sequences\n",
    "3. Define and train an LSTM model for predicting round outcomes\n",
    "4. Make predictions and visualize the results\n",
    "5. Evaluate the model's performance\n",
    "\n",
    "The model provides win probabilities at each time step of a round, which could be useful for real-time CS:GO match analysis and commentary."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
